<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Streaming TTS Demo</title>
</head>
<body>
  <button id="startBtn">Start WS Connection</button>
  <button id="stopBtn">Stop WS Connection</button>

  <h3>Transcripts (Partial / Final):</h3>
  <textarea id="transcriptLog" rows="10" cols="60" readonly></textarea>

  <script>
    let ws;
    let mediaRecorder;
    let mediaSource;
    let sourceBuffer;
    let audio;
    const chunkQueue = [];
    
    const transcriptBox = document.getElementById("transcriptLog");

    function appendTranscript(line) {
      transcriptBox.value += line + "\n";
    }

    document.getElementById('startBtn').onclick = async () => {
      try {
        // 1) Get user mic
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);

        // 2) Connect WebSocket to server
        ws = new WebSocket(`ws://${window.location.host}/stt`);
        ws.binaryType = 'arraybuffer';

        ws.onopen = () => {
          appendTranscript("[Browser] WS connected /stt");
        };
        ws.onclose = () => {
          appendTranscript("[Browser] WS closed");
        };
        ws.onerror = (err) => {
          console.error("[Browser] WS error:", err);
        };

        // 3) Setup MSE for streaming MP3 playback
        mediaSource = new MediaSource();
        audio = new Audio();
        audio.src = URL.createObjectURL(mediaSource);

        // The MediaSource is "closed" by default, wait for it to open
        mediaSource.addEventListener('sourceopen', onMediaSourceOpen);

        // 4) On receiving a message from server
        ws.onmessage = (evt) => {
          if (typeof evt.data === 'string') {
            // JSON => partial/final transcript
            try {
              const msg = JSON.parse(evt.data);
              if (msg.transcript) {
                if (msg.is_final) {
                  appendTranscript("[Final] " + msg.transcript);
                } else {
                  appendTranscript("[Partial] " + msg.transcript);
                }
              }
            } catch (err) {
              console.log("[Browser] Non-JSON text:", evt.data);
            }
          } else if (evt.data instanceof ArrayBuffer) {
            // We got a chunk of TTS MP3 data
            const chunk = new Uint8Array(evt.data);
            chunkQueue.push(chunk);
            appendNextChunk();
          }
        };

        // 5) Record mic audio in 300ms chunks => send to server
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0 && ws.readyState === WebSocket.OPEN) {
            e.data.arrayBuffer().then((buff) => {
              ws.send(buff);
            });
          }
        };

        mediaRecorder.start(300);
        appendTranscript("[Browser] Recording started...");
      } catch (err) {
        appendTranscript("[Browser] Error: " + err);
      }
    };

    function onMediaSourceOpen() {
      // Create a SourceBuffer for MP3
      sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
      sourceBuffer.addEventListener('updateend', appendNextChunk);
      // Attempt autoplay (some browsers require user interaction first)
      audio.play().catch(err => console.log("Autoplay blocked:", err));
    }

    function appendNextChunk() {
      if (!sourceBuffer || sourceBuffer.updating) return;
      if (chunkQueue.length > 0) {
        const nextChunk = chunkQueue.shift();
        sourceBuffer.appendBuffer(nextChunk);
      }
    }

    document.getElementById('stopBtn').onclick = () => {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
        appendTranscript("[Browser] Recording stopped.");
      }
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.close();
      }
      if (audio) {
        audio.pause();
      }
    };
  </script>
</body>
</html>
